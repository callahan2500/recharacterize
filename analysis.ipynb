{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recharacterize\n",
    "\n",
    "Large Language Models work by predicting the next token based on a series of prior tokens. Words are transformed into tokens through a \"chunking\" process. In this study, I want to pass a variety of sample text through different LLMs that has had a certain percentage of their characters removed and ask the model to try and write the original text. The goal here is to see how effective the tokenization process is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "#Models\n",
    "import openai\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import anthropic\n",
    "import os\n",
    "\n",
    "#Data\n",
    "from datasets import load_dataset\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "#Other\n",
    "import random\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get Sample Texts\n",
    "Using OpenAI's gpt-4o LLM, I created 500 randomly generated prompts and texts. I load these into dataframes here for analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_character_loss = pd.read_csv('character_loss_test.csv')\n",
    "#test_prompts = pd.read_csv('prompts_test.csv')\n",
    "\n",
    "test_prompts = pd.DataFrame([\"Describe a day in the life of a talking tree.\", \"If time travel were possible, where would you go first and why?\", \"Imagine a world where humans could breathe underwater. What would cities look like?\", \"Write a recipe for happiness using emotions as ingredients.\", \"If animals could vote, what might their political system look like?\", \n",
    "                             \"Describe an alien planet where the primary sense is taste instead of sight.\", \"Invent a new holiday and explain how people celebrate it.\", \"What would a diary entry from a robot gaining emotions sound like?\", \"Imagine a city built entirely out of glass. How does it function?\", \"Write a short letter from the moon to the Earth.\"], columns=['Prompts'])\n",
    "\n",
    "test_character_loss = pd.DataFrame([\"The moon hung low in the sky, its light shimmering on the surface of the lake. Lily dipped her toes into the cool water, imagining what it would feel like to swim beneath a glowing, silver moon. Somewhere in the distance, a frog croaked, adding its voice to the symphony of night.\",  \n",
    "\"A red kite soared high in the sky, its tail fluttering like a fiery ribbon. Sam held the string tightly, feeling the tug of the wind. It was as if the kite had a life of its own, pulling him toward the horizon and the adventures that lay beyond.\",  \n",
    "\"The old library smelled of leather and paper, and every corner seemed to whisper a story. Mia traced her fingers along the spines of the books, stopping when one seemed to hum beneath her touch. 'The Book of Forgotten Secrets' was embossed in gold, and her heart raced as she opened it.\",  \n",
    "\"The sound of waves crashing against the rocks was thunderous, but to Jake, it was calming. He imagined himself a pirate captain, standing on the deck of a great ship. With a wooden stick for a sword, he defended his ship from invisible enemies, his dog Max barking in support.\",  \n",
    "\"In the heart of the forest, an ancient oak tree stood taller than all the others. Its trunk was wide enough for three people to hug, and its branches stretched like arms toward the heavens. Beneath its shade, a tiny door was hidden. Ellie crouched down, wondering who—or what—might live inside.\",  \n",
    "\"The first snowfall of the year was magical. Sarah pressed her face against the frosty window, watching as the world outside turned white. Grabbing her scarf and mittens, she ran outside to build the first snowman of the season. She smiled as the snowflakes melted on her cheeks.\",  \n",
    "\"The attic was dusty and filled with forgotten treasures. Adam found an old telescope, its lens cracked but still usable. That night, he pointed it at the stars, wondering if anyone out there might be looking back at him through their own telescope.\",  \n",
    "\"The city buzzed with energy, neon lights flickering in every direction. Clara loved the way the streets came alive at night. Each alley seemed like a new path to a secret adventure, and every stranger she passed could be the start of a new story.\",  \n",
    "\"A single sunflower stood tall in the middle of the field, its bright yellow petals glowing like a sun of its own. Lucy knelt beside it, imagining it as the queen of the flowers, ruling over her green and golden kingdom.\",  \n",
    "\"The carnival was a whirlwind of colors, sounds, and smells. James loved the cotton candy the most, its sticky sweetness dissolving on his tongue. As the Ferris wheel took him higher, he felt like he could touch the stars, each one winking at him in the endless sky.\"\n",
    "], columns = [\"Text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Character Removal Functions\n",
    "\n",
    "In this step, we'll process all of the text and create a tuple which includes the original string accompanied by a new string that has a random percentage of its characters removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.15 #This is the percent of characters we seek to randomly remove. \n",
    "\n",
    "def remove_random_chars(input_string, loss):\n",
    "    num_to_remove = int(len(input_string) * loss)\n",
    "    \n",
    "    input_list = list(input_string)\n",
    "    \n",
    "    for _ in range(num_to_remove):\n",
    "        idx_to_remove = random.randint(0, len(input_list) - 1)\n",
    "        input_list.pop(idx_to_remove)\n",
    "    \n",
    "    output_string = ''.join(input_list)\n",
    "    return output_string\n",
    "\n",
    "def remove_spaces(input_string, loss):\n",
    "    if not (0 <= loss <= 1):\n",
    "        raise ValueError(\"Loss parameter must be between 0 and 1.\")\n",
    "    \n",
    "    spaces = [index for index, char in enumerate(input_string) if char == ' ']\n",
    "    num_to_remove = int(len(spaces) * loss)\n",
    "    spaces_to_remove = set(random.sample(spaces, num_to_remove))\n",
    "    \n",
    "    return ''.join(char for index, char in enumerate(input_string) if index not in spaces_to_remove)\n",
    "\n",
    "\n",
    "def remove_vowels(input_string, loss):\n",
    "\n",
    "    if not (0 <= loss <= 1):\n",
    "        raise ValueError(\"Loss parameter must be between 0 and 1.\")\n",
    "    \n",
    "    vowels = \"aeiouAEIOU\"\n",
    "    vowel_indices = [index for index, char in enumerate(input_string) if char in vowels]\n",
    "    num_to_remove = int(len(vowel_indices) * loss)\n",
    "    vowels_to_remove = set(random.sample(vowel_indices, num_to_remove))\n",
    "    \n",
    "    return ''.join(char for index, char in enumerate(input_string) if index not in vowels_to_remove)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Similarity & AI Rewrite Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity Functions\n",
    "\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1)\n",
    "    set2 = set(str2)\n",
    "    \n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    similarity = len(intersection) / len(union)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    return distance\n",
    "\n",
    "def normalized_levenshtein_similarity(str1, str2):\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    similarity = 1 - (distance / max_len)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def compute_cosine_similarity(str1, str2):\n",
    "\n",
    "    # Convert text to embeddings using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    embeddings = vectorizer.fit_transform([str1, str2])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(embeddings[0:1], embeddings[1:2])\n",
    "    \n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instructions_rewrite = \"The following text has had some of its characters removed. Try to rewrite to match the original text\"\n",
    "instructions_rewrite_anthropic = \"The following text has had some of its characters removed. Try to rewrite to match the original text. Only return the rewritten text, nothing other commentary\"\n",
    "instructions_prompt = \"You have received a prompt. Complete it\"\n",
    "\n",
    "#OPENAI\n",
    "def open_ai_rewrite(input_str, instructions):\n",
    "    openai.api_key = os.environ.get(\"OPENAI_KEY\")\n",
    "    assistant_key = os.environ.get(\"OPENAI_ASSISTANT_KEY\")\n",
    "\n",
    "    message = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = [\n",
    "            {\"role\":\"system\", \"content\": instructions},\n",
    "            {\"role\":\"user\", \"content\":input_str}\n",
    "\n",
    "        ]\n",
    "    )\n",
    "    return message.choices[0].message.content, message.usage.completion_tokens, message.usage.prompt_tokens\n",
    "\n",
    "\n",
    "#ANTHROPIC\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "def anthropic_rewrite(input_str, instructions):\n",
    "    anthropic_message = client.messages.create(\n",
    "        model = \"claude-3-opus-20240229\",\n",
    "        max_tokens = 1000,\n",
    "        temperature=0.0,\n",
    "        system=instructions,\n",
    "        messages=[\n",
    "            {\"role\":\"assistant\", \"content\": instructions},\n",
    "            {\"role\":\"user\", \"content\":input_str}\n",
    "        ]\n",
    "    )\n",
    "    return anthropic_message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ai_rewrite(input_str, instructions):\n",
    "    openai.api_key = os.environ.get(\"OPENAI_KEY\")\n",
    "    assistant_key = os.environ.get(\"OPENAI_ASSISTANT_KEY\")\n",
    "\n",
    "    message = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = [\n",
    "            {\"role\":\"system\", \"content\": instructions},\n",
    "            {\"role\":\"user\", \"content\":input_str}\n",
    "\n",
    "        ]\n",
    "    )\n",
    "    return message.choices[0].message.content, message.usage.completion_tokens, message.usage.prompt_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1 Rewrite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REWRITE# - OPENAI\n",
    "\n",
    "def experiment_1(df, removal_function, rewrite_function, instructions, loss_parameter):\n",
    "    df_exp1 = df.copy()\n",
    "    df_exp1['Loss Text'] = df_exp1['Text'].apply(lambda x: removal_function(x, loss_parameter))\n",
    "\n",
    "    df_exp1[['Attempted Rewrite', 'Input Tokens', 'Output Tokens']] = (\n",
    "    df_exp1['Loss Text']\n",
    "    .apply(lambda x: rewrite_function(x, instructions))\n",
    "    .apply(pd.Series) \n",
    "    )\n",
    "\n",
    "    #Similarity Tests\n",
    "    df_exp1['Jaccard Similarity'] = df_exp1.apply(lambda row: jaccard_similarity(row['Text'], row['Attempted Rewrite']), axis=1)\n",
    "    df_exp1['Levenshtein Distance'] = df_exp1.apply(lambda row: levenshtein_distance(row['Text'], row['Attempted Rewrite']), axis=1)\n",
    "    df_exp1['Normalized Levenshtein Distance'] = df_exp1.apply(lambda row: normalized_levenshtein_similarity(row['Text'], row['Attempted Rewrite']), axis=1)\n",
    "    df_exp1['Cosine Similarity'] = df_exp1.apply(lambda row: compute_cosine_similarity(row['Text'], row['Attempted Rewrite']), axis=1)\n",
    "\n",
    "    return df_exp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loss Parameter  Input Tokens Mean  Jaccard Similarity Mean  \\\n",
      "0             0.00               56.9                 1.000000   \n",
      "1             0.05               56.8                 1.000000   \n",
      "2             0.10               56.7                 1.000000   \n",
      "3             0.15               56.4                 0.993103   \n",
      "4             0.20               56.9                 0.990000   \n",
      "5             0.25               56.0                 0.972267   \n",
      "6             0.30               56.2                 0.967134   \n",
      "7             0.35               55.8                 0.918816   \n",
      "8             0.40               54.7                 0.933222   \n",
      "9             0.45               49.6                 0.872469   \n",
      "10            0.50               46.5                 0.874334   \n",
      "11            0.55               42.5                 0.829642   \n",
      "12            0.60               44.1                 0.806130   \n",
      "13            0.65               36.8                 0.777579   \n",
      "14            0.70               39.4                 0.772409   \n",
      "15            0.75               28.1                 0.716773   \n",
      "16            0.80               28.1                 0.724912   \n",
      "17            0.85               21.2                 0.686854   \n",
      "18            0.90               29.1                 0.674537   \n",
      "19            0.95               26.5                 0.638262   \n",
      "20            1.00               30.1                 0.699787   \n",
      "\n",
      "    Levenshtein Distance Mean  Normalized Levenshtein Distance Mean  \\\n",
      "0                         0.4                              0.998592   \n",
      "1                         0.2                              0.999242   \n",
      "2                         1.0                              0.996503   \n",
      "3                         1.7                              0.993336   \n",
      "4                         7.5                              0.970504   \n",
      "5                        18.3                              0.930400   \n",
      "6                        23.5                              0.911481   \n",
      "7                        54.7                              0.791916   \n",
      "8                        79.1                              0.702998   \n",
      "9                       125.8                              0.528728   \n",
      "10                      134.6                              0.491588   \n",
      "11                      153.7                              0.415937   \n",
      "12                      184.1                              0.332098   \n",
      "13                      184.7                              0.315759   \n",
      "14                      190.2                              0.304247   \n",
      "15                      195.0                              0.259853   \n",
      "16                      196.1                              0.255778   \n",
      "17                      207.1                              0.215793   \n",
      "18                      205.9                              0.218741   \n",
      "19                      214.8                              0.197013   \n",
      "20                      198.9                              0.246590   \n",
      "\n",
      "    Cosine Similarity Mean  \n",
      "0                 0.999778  \n",
      "1                 0.996202  \n",
      "2                 0.993630  \n",
      "3                 0.986527  \n",
      "4                 0.941140  \n",
      "5                 0.889261  \n",
      "6                 0.863465  \n",
      "7                 0.736563  \n",
      "8                 0.663010  \n",
      "9                 0.448521  \n",
      "10                0.392609  \n",
      "11                0.300836  \n",
      "12                0.172870  \n",
      "13                0.177612  \n",
      "14                0.200375  \n",
      "15                0.154956  \n",
      "16                0.125762  \n",
      "17                0.096726  \n",
      "18                0.107305  \n",
      "19                0.104768  \n",
      "20                0.116658  \n"
     ]
    }
   ],
   "source": [
    "#Random Character Removal\n",
    "loss = [0,0.05,.10,.15,.20,.25,.30,.35,.40,.45,.50,.55,.60,.65,.70,.75,.80,.85,.9,0.95,1]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in loss:\n",
    "    # Generate the DataFrame for the current loss parameter\n",
    "    df = experiment_1(test_character_loss, remove_random_chars, open_ai_rewrite, instructions_rewrite, i)\n",
    "    \n",
    "    # Calculate the means for the required columns\n",
    "    input_tokens_mean = df['Input Tokens'].mean()\n",
    "    jaccard_similarity_mean = df['Jaccard Similarity'].mean()\n",
    "    levenshtein_distance_mean = df['Levenshtein Distance'].mean()\n",
    "    normalized_levenshtein_distance_mean = df['Normalized Levenshtein Distance'].mean()\n",
    "    cosine_similarity_mean = df['Cosine Similarity'].mean()\n",
    "    \n",
    "    # Append the results as a dictionary\n",
    "    results.append({\n",
    "        'Loss Parameter': i,\n",
    "        'Input Tokens Mean': input_tokens_mean,\n",
    "        'Jaccard Similarity Mean': jaccard_similarity_mean,\n",
    "        'Levenshtein Distance Mean': levenshtein_distance_mean,\n",
    "        'Normalized Levenshtein Distance Mean': normalized_levenshtein_distance_mean,\n",
    "        'Cosine Similarity Mean': cosine_similarity_mean\n",
    "    })\n",
    "\n",
    "# Convert the results list into a Pandas DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(results_df)\n",
    "results_df.to_csv('experiment_1_openai_random_character_results.csv', index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loss Parameter  Input Tokens Mean  Jaccard Similarity Mean  \\\n",
      "0             0.00               57.0                 0.993750   \n",
      "1             0.05               56.9                 1.000000   \n",
      "2             0.10               56.8                 1.000000   \n",
      "3             0.15               56.8                 1.000000   \n",
      "4             0.20               56.8                 1.000000   \n",
      "5             0.25               56.9                 1.000000   \n",
      "6             0.30               56.8                 1.000000   \n",
      "7             0.35               56.9                 1.000000   \n",
      "8             0.40               56.8                 1.000000   \n",
      "9             0.45               56.9                 0.986437   \n",
      "10            0.50               56.9                 1.000000   \n",
      "11            0.55               56.9                 1.000000   \n",
      "12            0.60               56.8                 0.993103   \n",
      "13            0.65               56.8                 0.993333   \n",
      "14            0.70               56.8                 0.993103   \n",
      "15            0.75               56.8                 0.989878   \n",
      "16            0.80               56.9                 0.993333   \n",
      "17            0.85               56.8                 0.986437   \n",
      "18            0.90               56.9                 0.986437   \n",
      "19            0.95               57.0                 0.993103   \n",
      "\n",
      "    Levenshtein Distance Mean  Normalized Levenshtein Distance Mean  \\\n",
      "0                         0.9                              0.996817   \n",
      "1                         0.4                              0.998561   \n",
      "2                         0.0                              1.000000   \n",
      "3                         0.0                              1.000000   \n",
      "4                         0.0                              1.000000   \n",
      "5                         0.5                              0.998208   \n",
      "6                         0.0                              1.000000   \n",
      "7                         0.7                              0.997243   \n",
      "8                         0.2                              0.999286   \n",
      "9                         0.7                              0.997381   \n",
      "10                        0.5                              0.998076   \n",
      "11                        0.8                              0.997144   \n",
      "12                        0.8                              0.997022   \n",
      "13                        0.5                              0.998255   \n",
      "14                        0.8                              0.997041   \n",
      "15                        1.0                              0.996332   \n",
      "16                        0.3                              0.998935   \n",
      "17                        1.1                              0.995977   \n",
      "18                        1.9                              0.992825   \n",
      "19                        1.6                              0.993753   \n",
      "\n",
      "    Cosine Similarity Mean  \n",
      "0                 0.998222  \n",
      "1                 0.995379  \n",
      "2                 1.000000  \n",
      "3                 1.000000  \n",
      "4                 1.000000  \n",
      "5                 0.995379  \n",
      "6                 1.000000  \n",
      "7                 0.994783  \n",
      "8                 0.998082  \n",
      "9                 0.996851  \n",
      "10                0.995623  \n",
      "11                0.995157  \n",
      "12                0.997260  \n",
      "13                0.994841  \n",
      "14                0.996851  \n",
      "15                0.992218  \n",
      "16                0.994156  \n",
      "17                0.994399  \n",
      "18                0.988777  \n",
      "19                0.987167  \n"
     ]
    }
   ],
   "source": [
    "#Random Vowel Removal\n",
    "\n",
    "loss = [0,0.05,.10,.15,.20,.25,.30,.35,.40,.45,.50,.55,.60,.65,.70,.75,.80,.85,.9,0.95]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in loss:\n",
    "    # Generate the DataFrame for the current loss parameter\n",
    "    df = experiment_1(test_character_loss, remove_vowels, open_ai_rewrite, instructions_rewrite, i)\n",
    "    \n",
    "    # Calculate the means for the required columns\n",
    "    input_tokens_mean = df['Input Tokens'].mean()\n",
    "    jaccard_similarity_mean = df['Jaccard Similarity'].mean()\n",
    "    levenshtein_distance_mean = df['Levenshtein Distance'].mean()\n",
    "    normalized_levenshtein_distance_mean = df['Normalized Levenshtein Distance'].mean()\n",
    "    cosine_similarity_mean = df['Cosine Similarity'].mean()\n",
    "    \n",
    "    # Append the results as a dictionary\n",
    "    results.append({\n",
    "        'Loss Parameter': i,\n",
    "        'Input Tokens Mean': input_tokens_mean,\n",
    "        'Jaccard Similarity Mean': jaccard_similarity_mean,\n",
    "        'Levenshtein Distance Mean': levenshtein_distance_mean,\n",
    "        'Normalized Levenshtein Distance Mean': normalized_levenshtein_distance_mean,\n",
    "        'Cosine Similarity Mean': cosine_similarity_mean\n",
    "    })\n",
    "\n",
    "# Convert the results list into a Pandas DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(results_df)\n",
    "results_df.to_csv('experiment_1_openai_random_vowel_results.csv', index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loss Parameter  Input Tokens Mean  Jaccard Similarity Mean  \\\n",
      "0             0.00               56.9                      1.0   \n",
      "1             0.05               56.8                      1.0   \n",
      "2             0.10               56.9                      1.0   \n",
      "3             0.15               56.9                      1.0   \n",
      "4             0.20               56.8                      1.0   \n",
      "5             0.25               56.9                      1.0   \n",
      "6             0.30               56.8                      1.0   \n",
      "7             0.35               56.9                      1.0   \n",
      "8             0.40               56.8                      1.0   \n",
      "9             0.45               56.8                      1.0   \n",
      "10            0.50               56.8                      1.0   \n",
      "11            0.55               56.8                      1.0   \n",
      "12            0.60               56.8                      1.0   \n",
      "13            0.65               56.8                      1.0   \n",
      "14            0.70               56.8                      1.0   \n",
      "15            0.75               56.8                      1.0   \n",
      "16            0.80               56.8                      1.0   \n",
      "17            0.85               56.8                      1.0   \n",
      "18            0.90               56.8                      1.0   \n",
      "19            0.95               56.8                      1.0   \n",
      "\n",
      "    Levenshtein Distance Mean  Normalized Levenshtein Distance Mean  \\\n",
      "0                         0.3                              0.998925   \n",
      "1                         0.0                              1.000000   \n",
      "2                         0.3                              0.998925   \n",
      "3                         0.4                              0.998592   \n",
      "4                         0.0                              1.000000   \n",
      "5                         0.3                              0.998925   \n",
      "6                         0.0                              1.000000   \n",
      "7                         0.3                              0.998925   \n",
      "8                         0.0                              1.000000   \n",
      "9                         0.0                              1.000000   \n",
      "10                        0.0                              1.000000   \n",
      "11                        0.0                              1.000000   \n",
      "12                        0.0                              1.000000   \n",
      "13                        0.0                              1.000000   \n",
      "14                        0.0                              1.000000   \n",
      "15                        0.0                              1.000000   \n",
      "16                        0.0                              1.000000   \n",
      "17                        0.0                              1.000000   \n",
      "18                        0.0                              1.000000   \n",
      "19                        0.0                              1.000000   \n",
      "\n",
      "    Cosine Similarity Mean  \n",
      "0                 0.998444  \n",
      "1                 1.000000  \n",
      "2                 0.998444  \n",
      "3                 0.999778  \n",
      "4                 1.000000  \n",
      "5                 0.998444  \n",
      "6                 1.000000  \n",
      "7                 0.998444  \n",
      "8                 1.000000  \n",
      "9                 1.000000  \n",
      "10                1.000000  \n",
      "11                1.000000  \n",
      "12                1.000000  \n",
      "13                1.000000  \n",
      "14                1.000000  \n",
      "15                1.000000  \n",
      "16                1.000000  \n",
      "17                1.000000  \n",
      "18                1.000000  \n",
      "19                1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Random Space Removal\n",
    "\n",
    "loss = [0,0.05,.10,.15,.20,.25,.30,.35,.40,.45,.50,.55,.60,.65,.70,.75,.80,.85,.9,0.95,1]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in loss:\n",
    "    # Generate the DataFrame for the current loss parameter\n",
    "    df = experiment_1(test_character_loss, remove_spaces, open_ai_rewrite, instructions_rewrite, i)\n",
    "    \n",
    "    # Calculate the means for the required columns\n",
    "    input_tokens_mean = df['Input Tokens'].mean()\n",
    "    jaccard_similarity_mean = df['Jaccard Similarity'].mean()\n",
    "    levenshtein_distance_mean = df['Levenshtein Distance'].mean()\n",
    "    normalized_levenshtein_distance_mean = df['Normalized Levenshtein Distance'].mean()\n",
    "    cosine_similarity_mean = df['Cosine Similarity'].mean()\n",
    "    \n",
    "    # Append the results as a dictionary\n",
    "    results.append({\n",
    "        'Loss Parameter': i,\n",
    "        'Input Tokens Mean': input_tokens_mean,\n",
    "        'Jaccard Similarity Mean': jaccard_similarity_mean,\n",
    "        'Levenshtein Distance Mean': levenshtein_distance_mean,\n",
    "        'Normalized Levenshtein Distance Mean': normalized_levenshtein_distance_mean,\n",
    "        'Cosine Similarity Mean': cosine_similarity_mean\n",
    "    })\n",
    "\n",
    "# Convert the results list into a Pandas DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(results_df)\n",
    "results_df.to_csv('experiment_1_openai_random_spaces_results.csv', index=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m loss:\n\u001b[1;32m----> 8\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_character_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_random_chars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manthropic_rewrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions_rewrite_anthropic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     input_tokens_mean \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput Tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     11\u001b[0m     jaccard_similarity_mean \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaccard Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[1;32mIn[40], line 7\u001b[0m, in \u001b[0;36mexperiment_1\u001b[1;34m(df, removal_function, rewrite_function, instructions, loss_parameter)\u001b[0m\n\u001b[0;32m      4\u001b[0m df_exp1 \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      5\u001b[0m df_exp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss Text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_exp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: removal_function(x, loss_parameter))\n\u001b[1;32m----> 7\u001b[0m \u001b[43mdf_exp1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAttempted Rewrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput Tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutput Tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      8\u001b[0m df_exp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: rewrite_function(x, instructions))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries) \n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#Similarity Tests\u001b[39;00m\n\u001b[0;32m     14\u001b[0m df_exp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaccard Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_exp1\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: jaccard_similarity(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempted Rewrite\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ncare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32mc:\\Users\\ncare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4341\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4337\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[0;32m   4338\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[0;32m   4340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 4341\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m   4343\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[1;32mc:\\Users\\ncare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:390\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "#REWRITE# - ANTHROPIC\n",
    "\n",
    "#Remove Random Characters\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in loss:\n",
    "    df = experiment_1(test_character_loss, remove_random_chars, anthropic_rewrite, instructions_rewrite_anthropic, i)\n",
    "    \n",
    "    input_tokens_mean = df['Input Tokens'].mean()\n",
    "    jaccard_similarity_mean = df['Jaccard Similarity'].mean()\n",
    "    levenshtein_distance_mean = df['Levenshtein Distance'].mean()\n",
    "    normalized_levenshtein_distance_mean = df['Normalized Levenshtein Distance'].mean()\n",
    "    cosine_similarity_mean = df['Cosine Similarity'].mean()\n",
    "    \n",
    "    results.append({\n",
    "        'Loss Parameter': i,\n",
    "        'Input Tokens Mean': input_tokens_mean,\n",
    "        'Jaccard Similarity Mean': jaccard_similarity_mean,\n",
    "        'Levenshtein Distance Mean': levenshtein_distance_mean,\n",
    "        'Normalized Levenshtein Distance Mean': normalized_levenshtein_distance_mean,\n",
    "        'Cosine Similarity Mean': cosine_similarity_mean\n",
    "    })\n",
    "\n",
    "anthropic_results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(anthropic_results_df)\n",
    "anthropic_results_df.to_csv('experiment_1_anthropic_random_character_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Random Vowels\n",
    "results = []\n",
    "\n",
    "for i in loss:\n",
    "    df = experiment_1(test_character_loss, remove_vowels, anthropic_rewrite, instructions_rewrite_anthropic, i)\n",
    "    \n",
    "    input_tokens_mean = df['Input Tokens'].mean()\n",
    "    jaccard_similarity_mean = df['Jaccard Similarity'].mean()\n",
    "    levenshtein_distance_mean = df['Levenshtein Distance'].mean()\n",
    "    normalized_levenshtein_distance_mean = df['Normalized Levenshtein Distance'].mean()\n",
    "    cosine_similarity_mean = df['Cosine Similarity'].mean()\n",
    "    \n",
    "    results.append({\n",
    "        'Loss Parameter': i,\n",
    "        'Input Tokens Mean': input_tokens_mean,\n",
    "        'Jaccard Similarity Mean': jaccard_similarity_mean,\n",
    "        'Levenshtein Distance Mean': levenshtein_distance_mean,\n",
    "        'Normalized Levenshtein Distance Mean': normalized_levenshtein_distance_mean,\n",
    "        'Cosine Similarity Mean': cosine_similarity_mean\n",
    "    })\n",
    "\n",
    "anthropic_results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(anthropic_results_df)\n",
    "anthropic_results_df.to_csv('experiment_1_anthropic_random_vowels_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Random Spaces\n",
    "results = []\n",
    "\n",
    "for i in loss:\n",
    "    df = experiment_1(test_character_loss, remove_vowels, anthropic_rewrite, instructions_rewrite_anthropic, i)\n",
    "    \n",
    "    input_tokens_mean = df['Input Tokens'].mean()\n",
    "    jaccard_similarity_mean = df['Jaccard Similarity'].mean()\n",
    "    levenshtein_distance_mean = df['Levenshtein Distance'].mean()\n",
    "    normalized_levenshtein_distance_mean = df['Normalized Levenshtein Distance'].mean()\n",
    "    cosine_similarity_mean = df['Cosine Similarity'].mean()\n",
    "    \n",
    "    results.append({\n",
    "        'Loss Parameter': i,\n",
    "        'Input Tokens Mean': input_tokens_mean,\n",
    "        'Jaccard Similarity Mean': jaccard_similarity_mean,\n",
    "        'Levenshtein Distance Mean': levenshtein_distance_mean,\n",
    "        'Normalized Levenshtein Distance Mean': normalized_levenshtein_distance_mean,\n",
    "        'Cosine Similarity Mean': cosine_similarity_mean\n",
    "    })\n",
    "\n",
    "anthropic_results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display or save the DataFrame\n",
    "print(anthropic_results_df)\n",
    "anthropic_results_df.to_csv('experiment_1_anthropic_random_spaces_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPT# - OPENAI\n",
    "test_prompts_openai = test_prompts.copy()\n",
    "test_prompts_openai['Loss Prompts'] = test_prompts_openai['Prompts'].apply(lambda x: remove_random_chars(x, loss))\n",
    "test_prompts_openai[['Output with Loss Prompts', 'Input Tokens (Loss)', 'Output Tokens (Loss)']] = (\n",
    "    test_prompts_openai['Loss Prompts']\n",
    "    .apply(lambda x: open_ai_rewrite(x, instructions_prompt))\n",
    "    .apply(pd.Series) \n",
    ")\n",
    "\n",
    "test_prompts_openai[['Output with Original Prompts', 'Input Tokens (Original)', 'Output Tokens (Original)']] = (\n",
    "    test_prompts_openai['Prompts']\n",
    "    .apply(lambda x: open_ai_rewrite(x,instructions_prompt))\n",
    "    .apply(pd.Series)\n",
    ")\n",
    "\n",
    "test_prompts_openai[['Output with Original Prompts (Control)', 'Input Tokens (Control)', 'Output Tokens (Control)']] = (\n",
    "    test_prompts_openai['Prompts']\n",
    "    .apply(lambda x: open_ai_rewrite(x,instructions_prompt))\n",
    "    .apply(pd.Series)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity Columns - Control\n",
    "test_prompts_openai['Jaccard Similarity - Control'] = test_prompts_openai.apply(lambda row: jaccard_similarity(row['Output with Original Prompts'], row['Output with Original Prompts (Control)']), axis=1)\n",
    "test_prompts_openai['Levenshtein Distance - Control'] = test_prompts_openai.apply(lambda row: levenshtein_distance(row['Output with Original Prompts'], row['Output with Original Prompts (Control)']), axis=1)\n",
    "test_prompts_openai['Normalized Levenshtein Distance- Control'] = test_prompts_openai.apply(lambda row: normalized_levenshtein_similarity(row['Output with Original Prompts'], row['Output with Original Prompts (Control)']), axis=1)\n",
    "\n",
    "#Similarity Columns - Test\n",
    "test_prompts_openai['Jaccard Similarity - Test'] = test_prompts_openai.apply(lambda row: jaccard_similarity(row['Output with Loss Prompts'], row['Output with Original Prompts']), axis=1)\n",
    "test_prompts_openai['Levenshtein Distance - Test'] = test_prompts_openai.apply(lambda row: levenshtein_distance(row['Output with Loss Prompts'], row['Output with Original Prompts']), axis=1)\n",
    "test_prompts_openai['Normalized Levenshtein Distance- Test'] = test_prompts_openai.apply(lambda row: normalized_levenshtein_similarity(row['Output with Loss Prompts'], row['Output with Original Prompts']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompts</th>\n",
       "      <th>Loss Prompts</th>\n",
       "      <th>Output with Loss Prompts</th>\n",
       "      <th>Input Tokens (Loss)</th>\n",
       "      <th>Output Tokens (Loss)</th>\n",
       "      <th>Output with Original Prompts</th>\n",
       "      <th>Input Tokens (Original)</th>\n",
       "      <th>Output Tokens (Original)</th>\n",
       "      <th>Output with Original Prompts (Control)</th>\n",
       "      <th>Input Tokens (Control)</th>\n",
       "      <th>Output Tokens (Control)</th>\n",
       "      <th>Jaccard Similarity - Control</th>\n",
       "      <th>Levenshtein Distance - Control</th>\n",
       "      <th>Normalized Levenshtein Distance- Control</th>\n",
       "      <th>Jaccard Similarity - Test</th>\n",
       "      <th>Levenshtein Distance - Test</th>\n",
       "      <th>Normalized Levenshtein Distance- Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Describe a day in the life of a talking tree.</td>\n",
       "      <td>escribe ady n the lie of a alking tree.</td>\n",
       "      <td>Título: Un Día en la Vida de un Árbol Caminant...</td>\n",
       "      <td>674</td>\n",
       "      <td>32</td>\n",
       "      <td>In the heart of an ancient forest stands Telwy...</td>\n",
       "      <td>509</td>\n",
       "      <td>30</td>\n",
       "      <td>A day in the life of a talking tree unfolds wi...</td>\n",
       "      <td>537</td>\n",
       "      <td>30</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.279538</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>2134</td>\n",
       "      <td>0.249912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If time travel were possible, where would you ...</td>\n",
       "      <td>If time travel ere posile, where wouldou g fir...</td>\n",
       "      <td>If time travel were possible, choosing a desti...</td>\n",
       "      <td>107</td>\n",
       "      <td>34</td>\n",
       "      <td>If time travel were possible, visiting a momen...</td>\n",
       "      <td>99</td>\n",
       "      <td>33</td>\n",
       "      <td>If time travel were possible, one intriguing d...</td>\n",
       "      <td>105</td>\n",
       "      <td>33</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>477</td>\n",
       "      <td>0.258165</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>470</td>\n",
       "      <td>0.259843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imagine a world where humans could breathe und...</td>\n",
       "      <td>Imagnea ord where humanscoul beathe nderwte. W...</td>\n",
       "      <td>In a world where humans could breathe underwat...</td>\n",
       "      <td>430</td>\n",
       "      <td>40</td>\n",
       "      <td>In a world where humans could breathe underwat...</td>\n",
       "      <td>547</td>\n",
       "      <td>34</td>\n",
       "      <td>In a world where humans could breathe underwat...</td>\n",
       "      <td>511</td>\n",
       "      <td>34</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>2241</td>\n",
       "      <td>0.280347</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>2124</td>\n",
       "      <td>0.317919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a recipe for happiness using emotions as...</td>\n",
       "      <td>Wrta recipe forhppiness using emotions as ingr...</td>\n",
       "      <td>**Recipe for Happiness: Emotional Ingredients*...</td>\n",
       "      <td>520</td>\n",
       "      <td>31</td>\n",
       "      <td>**Recipe for Happiness**\\n\\n**Ingredients:**\\n...</td>\n",
       "      <td>553</td>\n",
       "      <td>29</td>\n",
       "      <td>**Recipe for Happiness**\\n\\n**Ingredients:**\\n...</td>\n",
       "      <td>547</td>\n",
       "      <td>29</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.288288</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1744</td>\n",
       "      <td>0.285831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If animals could vote, what might their politi...</td>\n",
       "      <td>If animals could vote, wht mg heir oliticalsys...</td>\n",
       "      <td>If animals could vote and had an organized pol...</td>\n",
       "      <td>492</td>\n",
       "      <td>35</td>\n",
       "      <td>If animals could vote, their political system ...</td>\n",
       "      <td>569</td>\n",
       "      <td>32</td>\n",
       "      <td>If animals could vote, their political system ...</td>\n",
       "      <td>534</td>\n",
       "      <td>32</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>2317</td>\n",
       "      <td>0.243305</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>2245</td>\n",
       "      <td>0.266819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Describe an alien planet where the primary sen...</td>\n",
       "      <td>Describe anlien lanet hre the rimy sene is ast...</td>\n",
       "      <td>Certainly! Imagine a distant alien planet name...</td>\n",
       "      <td>531</td>\n",
       "      <td>37</td>\n",
       "      <td>On this intriguing alien planet, where taste r...</td>\n",
       "      <td>519</td>\n",
       "      <td>33</td>\n",
       "      <td>On the alien planet of Gustarion, the primary ...</td>\n",
       "      <td>571</td>\n",
       "      <td>33</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>2201</td>\n",
       "      <td>0.290686</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>2133</td>\n",
       "      <td>0.258860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Invent a new holiday and explain how people ce...</td>\n",
       "      <td>nvent a new oliday and explainow peoe celerae it.</td>\n",
       "      <td>**Holiday Name:** Harmony Day\\n\\n**Date:** The...</td>\n",
       "      <td>432</td>\n",
       "      <td>35</td>\n",
       "      <td>Certainly! Let's introduce \"Global Harmony Day...</td>\n",
       "      <td>515</td>\n",
       "      <td>30</td>\n",
       "      <td>Holiday Name: Harmony Haven Day\\n\\nDate: Novem...</td>\n",
       "      <td>468</td>\n",
       "      <td>30</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2158</td>\n",
       "      <td>0.248607</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>2089</td>\n",
       "      <td>0.272632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What would a diary entry from a robot gaining ...</td>\n",
       "      <td>Wa would a dary entry rom obot gainig emotions...</td>\n",
       "      <td>**Date: 24th October 2023**\\n**Location: Robot...</td>\n",
       "      <td>512</td>\n",
       "      <td>34</td>\n",
       "      <td>**Diary Entry: November 5, 2023**\\n\\nToday mar...</td>\n",
       "      <td>467</td>\n",
       "      <td>32</td>\n",
       "      <td>**Diary Entry: October 30, 2023**\\n\\nInitializ...</td>\n",
       "      <td>515</td>\n",
       "      <td>32</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>1849</td>\n",
       "      <td>0.240033</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>1908</td>\n",
       "      <td>0.246445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Imagine a city built entirely out of glass. Ho...</td>\n",
       "      <td>Imagin  cit built enirely ut of glass How oe i...</td>\n",
       "      <td>Imagining a city built entirely out of glass b...</td>\n",
       "      <td>654</td>\n",
       "      <td>36</td>\n",
       "      <td>In a city built entirely out of glass, both ae...</td>\n",
       "      <td>551</td>\n",
       "      <td>33</td>\n",
       "      <td>In a city built entirely out of glass, the uni...</td>\n",
       "      <td>579</td>\n",
       "      <td>33</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>2416</td>\n",
       "      <td>0.289830</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>2599</td>\n",
       "      <td>0.290666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Write a short letter from the moon to the Earth.</td>\n",
       "      <td>Wite a sr letter from the mon to th Earh.</td>\n",
       "      <td>Dear Earth,\\n\\nI hope this letter finds you th...</td>\n",
       "      <td>331</td>\n",
       "      <td>32</td>\n",
       "      <td>Dear Earth,\\n\\nI hope this note finds you well...</td>\n",
       "      <td>213</td>\n",
       "      <td>30</td>\n",
       "      <td>Dear Earth,\\n\\nI hope this letter finds you vi...</td>\n",
       "      <td>291</td>\n",
       "      <td>30</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>959</td>\n",
       "      <td>0.308580</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>1160</td>\n",
       "      <td>0.298246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Prompts  \\\n",
       "0      Describe a day in the life of a talking tree.   \n",
       "1  If time travel were possible, where would you ...   \n",
       "2  Imagine a world where humans could breathe und...   \n",
       "3  Write a recipe for happiness using emotions as...   \n",
       "4  If animals could vote, what might their politi...   \n",
       "5  Describe an alien planet where the primary sen...   \n",
       "6  Invent a new holiday and explain how people ce...   \n",
       "7  What would a diary entry from a robot gaining ...   \n",
       "8  Imagine a city built entirely out of glass. Ho...   \n",
       "9   Write a short letter from the moon to the Earth.   \n",
       "\n",
       "                                        Loss Prompts  \\\n",
       "0            escribe ady n the lie of a alking tree.   \n",
       "1  If time travel ere posile, where wouldou g fir...   \n",
       "2  Imagnea ord where humanscoul beathe nderwte. W...   \n",
       "3  Wrta recipe forhppiness using emotions as ingr...   \n",
       "4  If animals could vote, wht mg heir oliticalsys...   \n",
       "5  Describe anlien lanet hre the rimy sene is ast...   \n",
       "6  nvent a new oliday and explainow peoe celerae it.   \n",
       "7  Wa would a dary entry rom obot gainig emotions...   \n",
       "8  Imagin  cit built enirely ut of glass How oe i...   \n",
       "9          Wite a sr letter from the mon to th Earh.   \n",
       "\n",
       "                            Output with Loss Prompts  Input Tokens (Loss)  \\\n",
       "0  Título: Un Día en la Vida de un Árbol Caminant...                  674   \n",
       "1  If time travel were possible, choosing a desti...                  107   \n",
       "2  In a world where humans could breathe underwat...                  430   \n",
       "3  **Recipe for Happiness: Emotional Ingredients*...                  520   \n",
       "4  If animals could vote and had an organized pol...                  492   \n",
       "5  Certainly! Imagine a distant alien planet name...                  531   \n",
       "6  **Holiday Name:** Harmony Day\\n\\n**Date:** The...                  432   \n",
       "7  **Date: 24th October 2023**\\n**Location: Robot...                  512   \n",
       "8  Imagining a city built entirely out of glass b...                  654   \n",
       "9  Dear Earth,\\n\\nI hope this letter finds you th...                  331   \n",
       "\n",
       "   Output Tokens (Loss)                       Output with Original Prompts  \\\n",
       "0                    32  In the heart of an ancient forest stands Telwy...   \n",
       "1                    34  If time travel were possible, visiting a momen...   \n",
       "2                    40  In a world where humans could breathe underwat...   \n",
       "3                    31  **Recipe for Happiness**\\n\\n**Ingredients:**\\n...   \n",
       "4                    35  If animals could vote, their political system ...   \n",
       "5                    37  On this intriguing alien planet, where taste r...   \n",
       "6                    35  Certainly! Let's introduce \"Global Harmony Day...   \n",
       "7                    34  **Diary Entry: November 5, 2023**\\n\\nToday mar...   \n",
       "8                    36  In a city built entirely out of glass, both ae...   \n",
       "9                    32  Dear Earth,\\n\\nI hope this note finds you well...   \n",
       "\n",
       "   Input Tokens (Original)  Output Tokens (Original)  \\\n",
       "0                      509                        30   \n",
       "1                       99                        33   \n",
       "2                      547                        34   \n",
       "3                      553                        29   \n",
       "4                      569                        32   \n",
       "5                      519                        33   \n",
       "6                      515                        30   \n",
       "7                      467                        32   \n",
       "8                      551                        33   \n",
       "9                      213                        30   \n",
       "\n",
       "              Output with Original Prompts (Control)  Input Tokens (Control)  \\\n",
       "0  A day in the life of a talking tree unfolds wi...                     537   \n",
       "1  If time travel were possible, one intriguing d...                     105   \n",
       "2  In a world where humans could breathe underwat...                     511   \n",
       "3  **Recipe for Happiness**\\n\\n**Ingredients:**\\n...                     547   \n",
       "4  If animals could vote, their political system ...                     534   \n",
       "5  On the alien planet of Gustarion, the primary ...                     571   \n",
       "6  Holiday Name: Harmony Haven Day\\n\\nDate: Novem...                     468   \n",
       "7  **Diary Entry: October 30, 2023**\\n\\nInitializ...                     515   \n",
       "8  In a city built entirely out of glass, the uni...                     579   \n",
       "9  Dear Earth,\\n\\nI hope this letter finds you vi...                     291   \n",
       "\n",
       "   Output Tokens (Control)  Jaccard Similarity - Control  \\\n",
       "0                       30                      0.734694   \n",
       "1                       33                      0.837838   \n",
       "2                       34                      0.852459   \n",
       "3                       29                      0.823529   \n",
       "4                       32                      0.861538   \n",
       "5                       33                      0.854167   \n",
       "6                       30                      0.777778   \n",
       "7                       32                      0.765625   \n",
       "8                       33                      0.781250   \n",
       "9                       30                      0.837209   \n",
       "\n",
       "   Levenshtein Distance - Control  Normalized Levenshtein Distance- Control  \\\n",
       "0                            1933                                  0.279538   \n",
       "1                             477                                  0.258165   \n",
       "2                            2241                                  0.280347   \n",
       "3                            1738                                  0.288288   \n",
       "4                            2317                                  0.243305   \n",
       "5                            2201                                  0.290686   \n",
       "6                            2158                                  0.248607   \n",
       "7                            1849                                  0.240033   \n",
       "8                            2416                                  0.289830   \n",
       "9                             959                                  0.308580   \n",
       "\n",
       "   Jaccard Similarity - Test  Levenshtein Distance - Test  \\\n",
       "0                   0.561404                         2134   \n",
       "1                   0.666667                          470   \n",
       "2                   0.838710                         2124   \n",
       "3                   0.785714                         1744   \n",
       "4                   0.835821                         2245   \n",
       "5                   0.780000                         2133   \n",
       "6                   0.718750                         2089   \n",
       "7                   0.803279                         1908   \n",
       "8                   0.772727                         2599   \n",
       "9                   0.734694                         1160   \n",
       "\n",
       "   Normalized Levenshtein Distance- Test  \n",
       "0                               0.249912  \n",
       "1                               0.259843  \n",
       "2                               0.317919  \n",
       "3                               0.285831  \n",
       "4                               0.266819  \n",
       "5                               0.258860  \n",
       "6                               0.272632  \n",
       "7                               0.246445  \n",
       "8                               0.290666  \n",
       "9                               0.298246  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROMPT# - ANTHROPIC\n",
    "test_prompts_anthropic = test_prompts.copy()\n",
    "\n",
    "test_prompts_anthropic['Loss Prompts'] = test_prompts_anthropic['Prompts'].apply(lambda x: remove_random_chars(x, loss))\n",
    "test_prompts_anthropic['Output with Loss Prompts'] = test_prompts_anthropic['Loss Prompts'].apply(lambda x: anthropic_rewrite(x, instructions_prompt))\n",
    "test_prompts_anthropic['Output with Original Prompts'] = test_prompts_anthropic['Prompts'].apply(lambda x: anthropic_rewrite(x,instructions_prompt))\n",
    "test_prompts_anthropic['Output with Original Prompts (Control)'] = test_prompts_anthropic['Prompts'].apply(lambda x: anthropic_rewrite(x,instructions_prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity Columns - Control\n",
    "test_prompts_anthropic['Jaccard Similarity - Control'] = test_prompts_anthropic.apply(lambda row: jaccard_similarity(row['Output with Original Prompts'], row['Output with Original Prompts (Control)']), axis=1)\n",
    "test_prompts_anthropic['Levenshtein Distance - Control'] = test_prompts_anthropic.apply(lambda row: levenshtein_distance(row['Output with Original Prompts'], row['Output with Original Prompts (Control)']), axis=1)\n",
    "test_prompts_anthropic['Normalized Levenshtein Distance- Control'] = test_prompts_anthropic.apply(lambda row: normalized_levenshtein_similarity(row['Output with Original Prompts'], row['Output with Original Prompts (Control)']), axis=1)\n",
    "\n",
    "#Similarity Columns - Test\n",
    "test_prompts_anthropic['Jaccard Similarity - Test'] = test_prompts_anthropic.apply(lambda row: jaccard_similarity(row['Output with Loss Prompts'], row['Output with Original Prompts']), axis=1)\n",
    "test_prompts_anthropic['Levenshtein Distance - Test'] = test_prompts_anthropic.apply(lambda row: levenshtein_distance(row['Output with Loss Prompts'], row['Output with Original Prompts']), axis=1)\n",
    "test_prompts_anthropic['Normalized Levenshtein Distance- Test'] = test_prompts_anthropic.apply(lambda row: normalized_levenshtein_similarity(row['Output with Loss Prompts'], row['Output with Original Prompts']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Loss Text</th>\n",
       "      <th>Attempted Rewrite</th>\n",
       "      <th>Jaccard Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Normalized Levenshtein Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The moon hung low in the sky, its light shimme...</td>\n",
       "      <td>The moon hung lown he skyits ligt shimringon t...</td>\n",
       "      <td>The moon hung low in the sky, its light shimme...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A red kite soared high in the sky, its tail fl...</td>\n",
       "      <td>A red kitesoared hih in thesky, its tailluteri...</td>\n",
       "      <td>A red kite soared high in the sky, its tail fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The old library smelled of leather and paper, ...</td>\n",
       "      <td>The od lbrr smelld of leahr and per, and very ...</td>\n",
       "      <td>The old library smelled of leather and paper, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sound of waves crashing against the rocks ...</td>\n",
       "      <td>The sond of wves rshig aainst he rocs was thun...</td>\n",
       "      <td>The sound of waves rushing against the rocks w...</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>11</td>\n",
       "      <td>0.960145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the heart of the forest, an ancient oak tre...</td>\n",
       "      <td>In the hart ofh foest, an ncientok tree stod t...</td>\n",
       "      <td>In the heart of the forest, an ancient oak tre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The first snowfall of the year was magical. Sa...</td>\n",
       "      <td>Thefrstswfall of the er ws mgcal. Sarhpresed h...</td>\n",
       "      <td>The first snowfall of the year was magical. Sa...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The attic was dusty and filled with forgotten ...</td>\n",
       "      <td>The attc was dutyand fillwith forotenreasre. A...</td>\n",
       "      <td>The attic was dusty and filled with forgotten ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The city buzzed with energy, neon lights flick...</td>\n",
       "      <td>Th city uzzed wih energ nen lgts flickerinin e...</td>\n",
       "      <td>The city buzzed with energy, neon lights flick...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A single sunflower stood tall in the middle of...</td>\n",
       "      <td>A snle unfower tood tallin the mddleo te field...</td>\n",
       "      <td>A single sunflower stood tall in the middle of...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The carnival was a whirlwind of colors, sounds...</td>\n",
       "      <td>The caniv wasa whrlwnd ofcor,sounds, nd smls. ...</td>\n",
       "      <td>The carnival was a whirlwind of color, sounds,...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  The moon hung low in the sky, its light shimme...   \n",
       "1  A red kite soared high in the sky, its tail fl...   \n",
       "2  The old library smelled of leather and paper, ...   \n",
       "3  The sound of waves crashing against the rocks ...   \n",
       "4  In the heart of the forest, an ancient oak tre...   \n",
       "5  The first snowfall of the year was magical. Sa...   \n",
       "6  The attic was dusty and filled with forgotten ...   \n",
       "7  The city buzzed with energy, neon lights flick...   \n",
       "8  A single sunflower stood tall in the middle of...   \n",
       "9  The carnival was a whirlwind of colors, sounds...   \n",
       "\n",
       "                                           Loss Text  \\\n",
       "0  The moon hung lown he skyits ligt shimringon t...   \n",
       "1  A red kitesoared hih in thesky, its tailluteri...   \n",
       "2  The od lbrr smelld of leahr and per, and very ...   \n",
       "3  The sond of wves rshig aainst he rocs was thun...   \n",
       "4  In the hart ofh foest, an ncientok tree stod t...   \n",
       "5  Thefrstswfall of the er ws mgcal. Sarhpresed h...   \n",
       "6  The attc was dutyand fillwith forotenreasre. A...   \n",
       "7  Th city uzzed wih energ nen lgts flickerinin e...   \n",
       "8  A snle unfower tood tallin the mddleo te field...   \n",
       "9  The caniv wasa whrlwnd ofcor,sounds, nd smls. ...   \n",
       "\n",
       "                                   Attempted Rewrite  Jaccard Similarity  \\\n",
       "0  The moon hung low in the sky, its light shimme...            1.000000   \n",
       "1  A red kite soared high in the sky, its tail fl...            1.000000   \n",
       "2  The old library smelled of leather and paper, ...            1.000000   \n",
       "3  The sound of waves rushing against the rocks w...            0.967742   \n",
       "4  In the heart of the forest, an ancient oak tre...            1.000000   \n",
       "5  The first snowfall of the year was magical. Sa...            1.000000   \n",
       "6  The attic was dusty and filled with forgotten ...            1.000000   \n",
       "7  The city buzzed with energy, neon lights flick...            1.000000   \n",
       "8  A single sunflower stood tall in the middle of...            1.000000   \n",
       "9  The carnival was a whirlwind of color, sounds,...            1.000000   \n",
       "\n",
       "   Levenshtein Distance  Normalized Levenshtein Distance  \n",
       "0                     0                         1.000000  \n",
       "1                     0                         1.000000  \n",
       "2                     1                         0.996503  \n",
       "3                    11                         0.960145  \n",
       "4                     0                         1.000000  \n",
       "5                     0                         1.000000  \n",
       "6                     1                         0.995968  \n",
       "7                     1                         0.995935  \n",
       "8                     1                         0.995434  \n",
       "9                     1                         0.996226  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_character_loss_anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Analysis\n",
    "\n",
    "In this step, we complete the following analyses:\n",
    "- Average string match at varying loss percentages (per model)\n",
    "- Average string match (how close the output is to the input per model based on string matching)\n",
    "- Average string match for different languages per model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
